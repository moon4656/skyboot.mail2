"""
DevOps ì„œë¹„ìŠ¤

SkyBoot Mail SaaS í”„ë¡œì íŠ¸ì˜ DevOps ê¸°ëŠ¥ì„ ìœ„í•œ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
ë°±ì—…, ë³µêµ¬, í…ŒìŠ¤íŠ¸ ë“±ì˜ DevOps ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import json
import uuid
import zipfile
import shutil
import psutil
import subprocess
import tempfile
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import logging
import asyncio
from sqlalchemy.orm import Session
from sqlalchemy import text, inspect

from ..config import settings
from ..model.user_model import User
from ..model.organization_model import Organization
from ..model.mail_model import Mail, MailUser, MailAttachment
from ..schemas.devops_schema import (
    BackupType, BackupStatus, RestoreType, TestType, TestStatus,
    BackupRequest, BackupResponse, BackupListResponse,
    RestoreRequest, RestoreResponse,
    TestRequest, TestResponse, TestResult,
    SystemHealthResponse, DevOpsResponse, JobStatusResponse
)

logger = logging.getLogger(__name__)

class DevOpsService:
    """DevOps ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, db: Session):
        self.db = db
        self.backup_dir = Path(settings.BACKUP_DIR if hasattr(settings, 'BACKUP_DIR') else "backups")
        self.backup_dir.mkdir(exist_ok=True)
        self.temp_dir = Path(tempfile.gettempdir()) / "skyboot_devops"
        self.temp_dir.mkdir(exist_ok=True)
        
        # ì‘ì—… ìƒíƒœ ì €ì¥ì†Œ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Redisë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
        self.job_status = {}
    
    # ===== ë°±ì—… ê¸°ëŠ¥ =====
    
    async def create_backup(
        self, 
        organization_id: int, 
        user_id: int, 
        request: BackupRequest
    ) -> BackupResponse:
        """ë°±ì—… ìƒì„±"""
        backup_id = str(uuid.uuid4())
        
        try:
            logger.info(f"ğŸ“¦ ë°±ì—… ì‹œì‘ - ì¡°ì§: {organization_id}, ì‚¬ìš©ì: {user_id}, íƒ€ì…: {request.backup_type}")
            
            # ë°±ì—… ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
            self.job_status[backup_id] = {
                "status": BackupStatus.RUNNING,
                "progress": 0,
                "started_at": datetime.now(),
                "log_messages": []
            }
            
            # ë°±ì—… íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"backup_{organization_id}_{timestamp}_{backup_id[:8]}.zip"
            backup_path = self.backup_dir / backup_filename
            
            # ë°±ì—… ì‹¤í–‰
            backup_size = await self._execute_backup(
                organization_id, backup_id, backup_path, request
            )
            
            # ë°±ì—… ì™„ë£Œ
            self.job_status[backup_id]["status"] = BackupStatus.COMPLETED
            self.job_status[backup_id]["progress"] = 100
            self.job_status[backup_id]["completed_at"] = datetime.now()
            
            logger.info(f"âœ… ë°±ì—… ì™„ë£Œ - ID: {backup_id}, í¬ê¸°: {backup_size} bytes")
            
            return BackupResponse(
                backup_id=backup_id,
                backup_type=request.backup_type,
                status=BackupStatus.COMPLETED,
                file_path=str(backup_path),
                file_size=backup_size,
                created_at=self.job_status[backup_id]["started_at"],
                completed_at=self.job_status[backup_id]["completed_at"],
                organization_id=organization_id,
                created_by=user_id,
                description=request.description,
                tags=request.tags,
                metadata={
                    "include_database": request.include_database,
                    "include_files": request.include_files,
                    "include_config": request.include_config,
                    "include_attachments": request.include_attachments,
                    "compression": request.compression,
                    "encryption": request.encryption
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ì‹¤íŒ¨ - ID: {backup_id}, ì˜¤ë¥˜: {str(e)}")
            self.job_status[backup_id]["status"] = BackupStatus.FAILED
            self.job_status[backup_id]["log_messages"].append(f"ë°±ì—… ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _execute_backup(
        self, 
        organization_id: int, 
        backup_id: str, 
        backup_path: Path, 
        request: BackupRequest
    ) -> int:
        """ë°±ì—… ì‹¤í–‰"""
        temp_backup_dir = self.temp_dir / f"backup_{backup_id}"
        temp_backup_dir.mkdir(exist_ok=True)
        
        try:
            progress = 0
            
            # ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
            if request.include_database:
                logger.info(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹œì‘ - ì¡°ì§: {organization_id}")
                await self._backup_database(organization_id, temp_backup_dir)
                progress += 30
                self.job_status[backup_id]["progress"] = progress
                self.job_status[backup_id]["log_messages"].append("ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ")
            
            # íŒŒì¼ ë°±ì—…
            if request.include_files:
                logger.info(f"ğŸ“ íŒŒì¼ ë°±ì—… ì‹œì‘ - ì¡°ì§: {organization_id}")
                await self._backup_files(organization_id, temp_backup_dir, request.include_attachments)
                progress += 40
                self.job_status[backup_id]["progress"] = progress
                self.job_status[backup_id]["log_messages"].append("íŒŒì¼ ë°±ì—… ì™„ë£Œ")
            
            # ì„¤ì • ë°±ì—…
            if request.include_config:
                logger.info(f"âš™ï¸ ì„¤ì • ë°±ì—… ì‹œì‘ - ì¡°ì§: {organization_id}")
                await self._backup_config(organization_id, temp_backup_dir)
                progress += 20
                self.job_status[backup_id]["progress"] = progress
                self.job_status[backup_id]["log_messages"].append("ì„¤ì • ë°±ì—… ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                "backup_id": backup_id,
                "organization_id": organization_id,
                "backup_type": request.backup_type,
                "created_at": datetime.now().isoformat(),
                "version": "1.0",
                "includes": {
                    "database": request.include_database,
                    "files": request.include_files,
                    "config": request.include_config,
                    "attachments": request.include_attachments
                }
            }
            
            metadata_file = temp_backup_dir / "backup_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # ZIP íŒŒì¼ ìƒì„±
            logger.info(f"ğŸ—œï¸ ë°±ì—… íŒŒì¼ ì••ì¶• ì‹œì‘")
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in temp_backup_dir.rglob('*'):
                    if file_path.is_file():
                        arcname = file_path.relative_to(temp_backup_dir)
                        zipf.write(file_path, arcname)
            
            progress = 100
            self.job_status[backup_id]["progress"] = progress
            self.job_status[backup_id]["log_messages"].append("ë°±ì—… íŒŒì¼ ì••ì¶• ì™„ë£Œ")
            
            return backup_path.stat().st_size
            
        finally:
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            if temp_backup_dir.exists():
                shutil.rmtree(temp_backup_dir)
    
    async def _backup_database(self, organization_id: int, backup_dir: Path):
        """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"""
        # ì¡°ì§ë³„ ë°ì´í„° ì¶”ì¶œ
        db_backup_dir = backup_dir / "database"
        db_backup_dir.mkdir(exist_ok=True)
        
        # ì‚¬ìš©ì ë°ì´í„°
        users = self.db.query(User).filter(User.organization_id == organization_id).all()
        users_data = [
            {
                "id": user.id,
                "user_uuid": user.user_uuid,
                "email": user.email,
                "username": user.username,
                "full_name": user.full_name,
                "is_active": user.is_active,
                "role": user.role.value if user.role else None,
                "created_at": user.created_at.isoformat() if user.created_at else None
            }
            for user in users
        ]
        
        with open(db_backup_dir / "users.json", 'w', encoding='utf-8') as f:
            json.dump(users_data, f, indent=2, ensure_ascii=False)
        
        # ë©”ì¼ ë°ì´í„°
        mails = self.db.query(Mail).filter(Mail.organization_id == organization_id).all()
        mails_data = [
            {
                "mail_id": mail.mail_id,
                "sender_id": mail.sender_id,
                "subject": mail.subject,
                "content": mail.content,
                "sent_at": mail.sent_at.isoformat() if mail.sent_at else None,
                "status": mail.status.value if mail.status else None
            }
            for mail in mails
        ]
        
        with open(db_backup_dir / "mails.json", 'w', encoding='utf-8') as f:
            json.dump(mails_data, f, indent=2, ensure_ascii=False)
    
    async def _backup_files(self, organization_id: int, backup_dir: Path, include_attachments: bool):
        """íŒŒì¼ ë°±ì—…"""
        files_backup_dir = backup_dir / "files"
        files_backup_dir.mkdir(exist_ok=True)
        
        if include_attachments:
            # ì²¨ë¶€íŒŒì¼ ë°±ì—…
            attachments_dir = files_backup_dir / "attachments"
            attachments_dir.mkdir(exist_ok=True)
            
            # ì¡°ì§ì˜ ì²¨ë¶€íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
            org_attachments_path = Path("attachments") / str(organization_id)
            if org_attachments_path.exists():
                shutil.copytree(org_attachments_path, attachments_dir / str(organization_id))
    
    async def _backup_config(self, organization_id: int, backup_dir: Path):
        """ì„¤ì • ë°±ì—…"""
        config_backup_dir = backup_dir / "config"
        config_backup_dir.mkdir(exist_ok=True)
        
        # ì¡°ì§ ì„¤ì •
        org = self.db.query(Organization).filter(Organization.id == organization_id).first()
        if org:
            org_config = {
                "id": org.id,
                "org_uuid": org.org_uuid,
                "name": org.name,
                "domain": org.domain,
                "max_users": org.max_users,
                "is_active": org.is_active,
                "created_at": org.created_at.isoformat() if org.created_at else None
            }
            
            with open(config_backup_dir / "organization.json", 'w', encoding='utf-8') as f:
                json.dump(org_config, f, indent=2, ensure_ascii=False)
    
    # ===== ë³µêµ¬ ê¸°ëŠ¥ =====
    
    async def restore_backup(
        self, 
        organization_id: int, 
        user_id: int, 
        request: RestoreRequest
    ) -> RestoreResponse:
        """ë°±ì—… ë³µêµ¬"""
        restore_id = str(uuid.uuid4())
        
        try:
            logger.info(f"ğŸ”„ ë³µêµ¬ ì‹œì‘ - ì¡°ì§: {organization_id}, ë°±ì—…: {request.backup_id}")
            
            # ë³µêµ¬ ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
            self.job_status[restore_id] = {
                "status": BackupStatus.RUNNING,
                "progress": 0,
                "started_at": datetime.now(),
                "log_messages": []
            }
            
            # ë°±ì—… íŒŒì¼ ì°¾ê¸°
            backup_file = await self._find_backup_file(request.backup_id)
            if not backup_file:
                raise FileNotFoundError(f"ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.backup_id}")
            
            # ë³µêµ¬ ì‹¤í–‰
            await self._execute_restore(
                organization_id, restore_id, backup_file, request
            )
            
            # ë³µêµ¬ ì™„ë£Œ
            self.job_status[restore_id]["status"] = BackupStatus.COMPLETED
            self.job_status[restore_id]["progress"] = 100
            self.job_status[restore_id]["completed_at"] = datetime.now()
            
            logger.info(f"âœ… ë³µêµ¬ ì™„ë£Œ - ID: {restore_id}")
            
            return RestoreResponse(
                restore_id=restore_id,
                backup_id=request.backup_id,
                restore_type=request.restore_type,
                status=BackupStatus.COMPLETED,
                started_at=self.job_status[restore_id]["started_at"],
                completed_at=self.job_status[restore_id]["completed_at"],
                organization_id=organization_id,
                restored_by=user_id,
                progress=100,
                log_messages=self.job_status[restore_id]["log_messages"]
            )
            
        except Exception as e:
            logger.error(f"âŒ ë³µêµ¬ ì‹¤íŒ¨ - ID: {restore_id}, ì˜¤ë¥˜: {str(e)}")
            self.job_status[restore_id]["status"] = BackupStatus.FAILED
            self.job_status[restore_id]["log_messages"].append(f"ë³µêµ¬ ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _find_backup_file(self, backup_id: str) -> Optional[Path]:
        """ë°±ì—… íŒŒì¼ ì°¾ê¸°"""
        for backup_file in self.backup_dir.glob("*.zip"):
            if backup_id in backup_file.name:
                return backup_file
        return None
    
    async def _execute_restore(
        self, 
        organization_id: int, 
        restore_id: str, 
        backup_file: Path, 
        request: RestoreRequest
    ):
        """ë³µêµ¬ ì‹¤í–‰"""
        temp_restore_dir = self.temp_dir / f"restore_{restore_id}"
        temp_restore_dir.mkdir(exist_ok=True)
        
        try:
            # ë°±ì—… íŒŒì¼ ì••ì¶• í•´ì œ
            with zipfile.ZipFile(backup_file, 'r') as zipf:
                zipf.extractall(temp_restore_dir)
            
            progress = 20
            self.job_status[restore_id]["progress"] = progress
            self.job_status[restore_id]["log_messages"].append("ë°±ì—… íŒŒì¼ ì••ì¶• í•´ì œ ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„° í™•ì¸
            metadata_file = temp_restore_dir / "backup_metadata.json"
            if metadata_file.exists():
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                logger.info(f"ğŸ“‹ ë°±ì—… ë©”íƒ€ë°ì´í„°: {metadata}")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
            if request.restore_database:
                await self._restore_database(organization_id, temp_restore_dir, request.overwrite_existing)
                progress += 40
                self.job_status[restore_id]["progress"] = progress
                self.job_status[restore_id]["log_messages"].append("ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì™„ë£Œ")
            
            # íŒŒì¼ ë³µêµ¬
            if request.restore_files:
                await self._restore_files(organization_id, temp_restore_dir, request.overwrite_existing)
                progress += 30
                self.job_status[restore_id]["progress"] = progress
                self.job_status[restore_id]["log_messages"].append("íŒŒì¼ ë³µêµ¬ ì™„ë£Œ")
            
            # ì„¤ì • ë³µêµ¬
            if request.restore_config:
                await self._restore_config(organization_id, temp_restore_dir, request.overwrite_existing)
                progress += 10
                self.job_status[restore_id]["progress"] = progress
                self.job_status[restore_id]["log_messages"].append("ì„¤ì • ë³µêµ¬ ì™„ë£Œ")
            
        finally:
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            if temp_restore_dir.exists():
                shutil.rmtree(temp_restore_dir)
    
    async def _restore_database(self, organization_id: int, restore_dir: Path, overwrite: bool):
        """ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬"""
        db_restore_dir = restore_dir / "database"
        if not db_restore_dir.exists():
            return
        
        # ì‚¬ìš©ì ë°ì´í„° ë³µêµ¬
        users_file = db_restore_dir / "users.json"
        if users_file.exists():
            with open(users_file, 'r', encoding='utf-8') as f:
                users_data = json.load(f)
            
            for user_data in users_data:
                existing_user = self.db.query(User).filter(
                    User.user_uuid == user_data["user_uuid"]
                ).first()
                
                if existing_user and not overwrite:
                    continue
                
                # ì‚¬ìš©ì ë³µêµ¬ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•˜ê²Œ)
                logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë³µêµ¬: {user_data['email']}")
    
    async def _restore_files(self, organization_id: int, restore_dir: Path, overwrite: bool):
        """íŒŒì¼ ë³µêµ¬"""
        files_restore_dir = restore_dir / "files"
        if not files_restore_dir.exists():
            return
        
        # ì²¨ë¶€íŒŒì¼ ë³µêµ¬
        attachments_restore_dir = files_restore_dir / "attachments" / str(organization_id)
        if attachments_restore_dir.exists():
            target_dir = Path("attachments") / str(organization_id)
            target_dir.mkdir(parents=True, exist_ok=True)
            
            if overwrite or not target_dir.exists():
                shutil.copytree(attachments_restore_dir, target_dir, dirs_exist_ok=True)
    
    async def _restore_config(self, organization_id: int, restore_dir: Path, overwrite: bool):
        """ì„¤ì • ë³µêµ¬"""
        config_restore_dir = restore_dir / "config"
        if not config_restore_dir.exists():
            return
        
        # ì¡°ì§ ì„¤ì • ë³µêµ¬
        org_file = config_restore_dir / "organization.json"
        if org_file.exists():
            with open(org_file, 'r', encoding='utf-8') as f:
                org_data = json.load(f)
            
            logger.info(f"ğŸ¢ ì¡°ì§ ì„¤ì • ë³µêµ¬: {org_data['name']}")
    
    # ===== í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥ =====
    
    async def run_tests(
        self, 
        organization_id: int, 
        user_id: int, 
        request: TestRequest
    ) -> TestResponse:
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        test_id = str(uuid.uuid4())
        
        try:
            logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘ - ì¡°ì§: {organization_id}, í…ŒìŠ¤íŠ¸: {request.test_types}")
            
            started_at = datetime.now()
            results = []
            
            for test_type in request.test_types:
                result = await self._run_single_test(test_type, organization_id)
                results.append(result)
            
            completed_at = datetime.now()
            total_execution_time = (completed_at - started_at).total_seconds()
            
            # ì „ì²´ ìƒíƒœ ê³„ì‚°
            passed_tests = sum(1 for r in results if r.status == TestStatus.PASS)
            failed_tests = sum(1 for r in results if r.status == TestStatus.FAIL)
            warning_tests = sum(1 for r in results if r.status == TestStatus.WARNING)
            
            if failed_tests > 0:
                overall_status = TestStatus.FAIL
            elif warning_tests > 0:
                overall_status = TestStatus.WARNING
            else:
                overall_status = TestStatus.PASS
            
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ID: {test_id}, ìƒíƒœ: {overall_status}")
            
            return TestResponse(
                test_id=test_id,
                overall_status=overall_status,
                total_tests=len(results),
                passed_tests=passed_tests,
                failed_tests=failed_tests,
                warning_tests=warning_tests,
                results=results,
                started_at=started_at,
                completed_at=completed_at,
                total_execution_time=total_execution_time,
                organization_id=organization_id,
                executed_by=user_id
            )
            
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ID: {test_id}, ì˜¤ë¥˜: {str(e)}")
            raise
    
    async def _run_single_test(self, test_type: TestType, organization_id: int) -> TestResult:
        """ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        start_time = datetime.now()
        
        try:
            if test_type == TestType.HEALTH_CHECK:
                return await self._test_health_check()
            elif test_type == TestType.SYSTEM_STATUS:
                return await self._test_system_status()
            elif test_type == TestType.DATABASE_CHECK:
                return await self._test_database_check()
            elif test_type == TestType.MAIL_SERVER_CHECK:
                return await self._test_mail_server_check()
            elif test_type == TestType.PERFORMANCE_TEST:
                return await self._test_performance()
            elif test_type == TestType.SECURITY_SCAN:
                return await self._test_security_scan()
            elif test_type == TestType.INTEGRATION_TEST:
                return await self._test_integration()
            else:
                return TestResult(
                    test_type=test_type,
                    status=TestStatus.SKIP,
                    message="ì§€ì›í•˜ì§€ ì•ŠëŠ” í…ŒìŠ¤íŠ¸ íƒ€ì…ì…ë‹ˆë‹¤",
                    details={},
                    execution_time=0.0,
                    timestamp=start_time
                )
                
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=test_type,
                status=TestStatus.ERROR,
                message=f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_health_check(self) -> TestResult:
        """í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            # ê¸°ë³¸ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            details = {
                "cpu_usage": cpu_percent,
                "memory_usage": memory.percent,
                "disk_usage": disk.percent,
                "available_memory": memory.available,
                "free_disk": disk.free
            }
            
            # ìƒíƒœ íŒì •
            if cpu_percent > 90 or memory.percent > 90 or disk.percent > 90:
                status = TestStatus.FAIL
                message = "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤"
            elif cpu_percent > 70 or memory.percent > 70 or disk.percent > 80:
                status = TestStatus.WARNING
                message = "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤"
            else:
                status = TestStatus.PASS
                message = "ì‹œìŠ¤í…œ ìƒíƒœê°€ ì •ìƒì…ë‹ˆë‹¤"
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TestResult(
                test_type=TestType.HEALTH_CHECK,
                status=status,
                message=message,
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.HEALTH_CHECK,
                status=TestStatus.ERROR,
                message=f"í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_system_status(self) -> TestResult:
        """ì‹œìŠ¤í…œ ìƒíƒœ í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
            boot_time = datetime.fromtimestamp(psutil.boot_time())
            uptime = datetime.now() - boot_time
            
            details = {
                "boot_time": boot_time.isoformat(),
                "uptime_seconds": uptime.total_seconds(),
                "uptime_days": uptime.days,
                "load_average": os.getloadavg() if hasattr(os, 'getloadavg') else None,
                "process_count": len(psutil.pids())
            }
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TestResult(
                test_type=TestType.SYSTEM_STATUS,
                status=TestStatus.PASS,
                message="ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ",
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.SYSTEM_STATUS,
                status=TestStatus.ERROR,
                message=f"ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_database_check(self) -> TestResult:
        """ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
            result = self.db.execute(text("SELECT 1")).scalar()
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            inspector = inspect(self.db.bind)
            tables = inspector.get_table_names()
            
            details = {
                "connection_test": result == 1,
                "table_count": len(tables),
                "tables": tables[:10]  # ì²˜ìŒ 10ê°œ í…Œì´ë¸”ë§Œ
            }
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TestResult(
                test_type=TestType.DATABASE_CHECK,
                status=TestStatus.PASS,
                message="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° êµ¬ì¡° í™•ì¸ ì™„ë£Œ",
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.DATABASE_CHECK,
                status=TestStatus.FAIL,
                message=f"ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_mail_server_check(self) -> TestResult:
        """ë©”ì¼ ì„œë²„ ì²´í¬ í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            # ë©”ì¼ ì„œë²„ ìƒíƒœ í™•ì¸ (ê°„ë‹¨í•œ êµ¬í˜„)
            details = {
                "smtp_status": "unknown",
                "imap_status": "unknown",
                "postfix_status": "unknown",
                "dovecot_status": "unknown"
            }
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë©”ì¼ ì„œë²„ í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸
            # ì˜ˆ: subprocessë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TestResult(
                test_type=TestType.MAIL_SERVER_CHECK,
                status=TestStatus.WARNING,
                message="ë©”ì¼ ì„œë²„ ìƒíƒœ í™•ì¸ ê¸°ëŠ¥ì´ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.MAIL_SERVER_CHECK,
                status=TestStatus.ERROR,
                message=f"ë©”ì¼ ì„œë²„ ì²´í¬ ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_performance(self) -> TestResult:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            # ê°„ë‹¨í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            db_start = datetime.now()
            self.db.execute(text("SELECT COUNT(*) FROM users")).scalar()
            db_time = (datetime.now() - db_start).total_seconds()
            
            details = {
                "database_query_time": db_time,
                "database_performance": "good" if db_time < 0.1 else "slow"
            }
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            status = TestStatus.PASS if db_time < 0.5 else TestStatus.WARNING
            message = f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - DB ì¿¼ë¦¬ ì‹œê°„: {db_time:.3f}ì´ˆ"
            
            return TestResult(
                test_type=TestType.PERFORMANCE_TEST,
                status=status,
                message=message,
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.PERFORMANCE_TEST,
                status=TestStatus.ERROR,
                message=f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_security_scan(self) -> TestResult:
        """ë³´ì•ˆ ìŠ¤ìº” í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            details = {
                "security_scan": "basic_check_only",
                "note": "ê³ ê¸‰ ë³´ì•ˆ ìŠ¤ìº” ê¸°ëŠ¥ì€ ë³„ë„ êµ¬í˜„ í•„ìš”"
            }
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TestResult(
                test_type=TestType.SECURITY_SCAN,
                status=TestStatus.WARNING,
                message="ê¸°ë³¸ ë³´ì•ˆ ì²´í¬ë§Œ ìˆ˜í–‰ë¨",
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.SECURITY_SCAN,
                status=TestStatus.ERROR,
                message=f"ë³´ì•ˆ ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    async def _test_integration(self) -> TestResult:
        """í†µí•© í…ŒìŠ¤íŠ¸"""
        start_time = datetime.now()
        
        try:
            details = {
                "integration_test": "placeholder",
                "note": "í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„ í•„ìš”"
            }
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TestResult(
                test_type=TestType.INTEGRATION_TEST,
                status=TestStatus.SKIP,
                message="í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ê°€ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                details=details,
                execution_time=execution_time,
                timestamp=start_time
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return TestResult(
                test_type=TestType.INTEGRATION_TEST,
                status=TestStatus.ERROR,
                message=f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}",
                details={"error": str(e)},
                execution_time=execution_time,
                timestamp=start_time
            )
    
    # ===== ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ =====
    
    async def get_system_health(self) -> SystemHealthResponse:
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
        try:
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´
            cpu_usage = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            boot_time = datetime.fromtimestamp(psutil.boot_time())
            uptime = (datetime.now() - boot_time).total_seconds()
            
            # ì„œë¹„ìŠ¤ ìƒíƒœ (ê°„ë‹¨í•œ êµ¬í˜„)
            services = {
                "fastapi": {"status": "running", "uptime": uptime},
                "database": {"status": "unknown", "last_check": datetime.now().isoformat()},
                "redis": {"status": "unknown", "last_check": datetime.now().isoformat()},
                "mail_server": {"status": "unknown", "last_check": datetime.now().isoformat()}
            }
            
            # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
            try:
                self.db.execute(text("SELECT 1")).scalar()
                db_status = "healthy"
            except:
                db_status = "error"
            
            database = {
                "status": db_status,
                "connection_pool": "unknown",
                "last_check": datetime.now().isoformat()
            }
            
            # ì „ì²´ ìƒíƒœ íŒì •
            if cpu_usage > 90 or memory.percent > 90 or disk.percent > 90 or db_status == "error":
                overall_status = "critical"
            elif cpu_usage > 70 or memory.percent > 70 or disk.percent > 80:
                overall_status = "warning"
            else:
                overall_status = "healthy"
            
            return SystemHealthResponse(
                status=overall_status,
                timestamp=datetime.now(),
                services=services,
                database=database,
                mail_server={"status": "unknown", "last_check": datetime.now().isoformat()},
                redis={"status": "unknown", "last_check": datetime.now().isoformat()},
                disk_usage={
                    "total": disk.total,
                    "used": disk.used,
                    "free": disk.free,
                    "percent": disk.percent
                },
                memory_usage={
                    "total": memory.total,
                    "used": memory.used,
                    "available": memory.available,
                    "percent": memory.percent
                },
                cpu_usage=cpu_usage,
                uptime=uptime
            )
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {str(e)}")
            raise
    
    # ===== ì‘ì—… ìƒíƒœ ì¡°íšŒ =====
    
    async def get_job_status(self, job_id: str) -> Optional[JobStatusResponse]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        if job_id not in self.job_status:
            return None
        
        job_info = self.job_status[job_id]
        
        return JobStatusResponse(
            job_id=job_id,
            job_type="backup" if "backup" in job_id else "restore",
            status=job_info["status"],
            progress=job_info.get("progress", 0),
            started_at=job_info["started_at"],
            updated_at=job_info.get("updated_at", job_info["started_at"]),
            estimated_completion=job_info.get("estimated_completion"),
            log_messages=job_info.get("log_messages", []),
            result=job_info.get("result")
        )
    
    # ===== ë°±ì—… ëª©ë¡ ì¡°íšŒ =====
    
    async def list_backups(
        self, 
        organization_id: int, 
        page: int = 1, 
        limit: int = 20
    ) -> BackupListResponse:
        """ë°±ì—… ëª©ë¡ ì¡°íšŒ"""
        try:
            # ë°±ì—… íŒŒì¼ ëª©ë¡ ì¡°íšŒ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ)
            backup_files = list(self.backup_dir.glob("*.zip"))
            
            # ì¡°ì§ë³„ í•„í„°ë§ (íŒŒì¼ëª…ì—ì„œ ì¡°ì§ ID ì¶”ì¶œ)
            org_backups = []
            for backup_file in backup_files:
                if f"_{organization_id}_" in backup_file.name:
                    # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                    stat = backup_file.stat()
                    backup_id = backup_file.stem.split('_')[-1] if '_' in backup_file.stem else backup_file.stem
                    
                    org_backups.append(BackupResponse(
                        backup_id=backup_id,
                        backup_type=BackupType.FULL,  # ê¸°ë³¸ê°’
                        status=BackupStatus.COMPLETED,
                        file_path=str(backup_file),
                        file_size=stat.st_size,
                        created_at=datetime.fromtimestamp(stat.st_ctime),
                        completed_at=datetime.fromtimestamp(stat.st_mtime),
                        organization_id=organization_id,
                        created_by=0,  # ì•Œ ìˆ˜ ì—†ìŒ
                        description=None,
                        tags=[],
                        metadata={}
                    ))
            
            # í˜ì´ì§•
            total = len(org_backups)
            start = (page - 1) * limit
            end = start + limit
            paginated_backups = org_backups[start:end]
            
            return BackupListResponse(
                backups=paginated_backups,
                total=total,
                page=page,
                limit=limit
            )
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise